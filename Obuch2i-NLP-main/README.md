# Результаты исследования

## Как читать результаты

### Исследуются три типа метрик:

Precision - доля корректно исправленных ошибок среди всех ошибок, найденных моделью. Эта метрика важна, если нам важно не допустить "наезд" на ученика - когда детектировали ошибку, а на самом деле ошибки нет.

Recall - доля ошибок, найденных моделью, среди всех ошибок, содержащихся в датасете. Эта метрика важна, если мы хотим детектировать максимум ошибок (но могут быть ложные срабатывания).

F1 - среднее гармоническое от (Precision, Recall). Среднее от метрик выше :)

### Перед метриками проставлены префиксы

Пустой префикс - побуквенная оценка метрик

Errant - способ более точного подсчета метрик по орфографии (значения получаются ниже, но более репрезентативны)

Punct - метрики на пунктуационных ошибках

Case - метрики для заглавной/строчной букв

### Ссылки в таблице

Дашборд эксперимента - подробная человеко-читаемая информация об эксперименте на сервисе WandB: метрики качества модели, состояние и нагрузка на систему, результат предсказаний модели, сниппеты датасетов и тд

(**если нет доступа к дашборду - пиши a@tunyatk.in**)

Ноутбук - код (jupyter notebook), благодаря которому были получены результаты экспериментов

## Исправление орфографии

|  Модель  | Errant Precision | Errant Recall | Errant F1 | Precision | Recall | F1
|----------|----------|----------|----------|----------|----------|----------|
| language_tool_python ([дашборд эксперимента](https://wandb.ai/obuchii/NLP%20Scoring/runs/lkrlnnk2), [ноутбук](.experiments/001-model_comparison/002-language_tool_python.ipynb))   | 36.53   | 32.75   | 34.53    | 45.2   | 35.49   | 39.76    |
| Yandex Speller  ([дашборд эксперимента](https://wandb.ai/obuchii/NLP%20Scoring/runs/mjvb28xc), [ноутбук](.experiments/001-model_comparison/004-yandex_speller.ipynb))  | 61.97   | 49.78   | 55.21   | 70.12   | 49.95   | 58.34   |
| sage-fredt5-distilled-95m ([дашборд эксперимента](https://wandb.ai/obuchii/transformer_spellers/runs/cj4hf61p), [ноутбук](.experiments/001-model_comparison/005-transformers.ipynb))  | 64.74   | 68.91   | 66.76    | 82.19   | 77.25   | 79.65   |
| sage-fredt5-large  ([дашборд эксперимента](https://wandb.ai/obuchii/transformer_spellers/runs/w4g1na9g), [ноутбук](.experiments/001-model_comparison/005-transformers.ipynb)) | 52.07   | 67.5   | 58.79   | 56.75  | 70.58  | 62.91    |





## Исправление пунктуации



|  Задача | Punct Precision | Punct Recall | Punct F1 | Case Precision | Case Recall | Case F1
|----------|----------|----------|----------|----------|----------|----------|
| language_tool_python ([дашборд эксперимента](https://wandb.ai/obuchii/NLP%20Scoring/runs/lkrlnnk2), [ноутбук](.experiments/001-model_comparison/002-language_tool_python.ipynb))      | 41.94   | 0.22   | 0.45    | 66.27  | 78.56   | 71.9    |
| Yandex Speller  ([дашборд эксперимента](https://wandb.ai/obuchii/NLP%20Scoring/runs/mjvb28xc), [ноутбук](.experiments/001-model_comparison/004-yandex_speller.ipynb))   | 100   | 0   | 0    | 100.0  | 0   | 0    |
| sage-fredt5-distilled-95m ([дашборд эксперимента](https://wandb.ai/obuchii/transformer_spellers/runs/21macwva), [ноутбук](.experiments/001-model_comparison/005-transformers.ipynb))   | 86.78   | 80.57   | 83.56   |  94.37  | 92.55   | 93.45   |
| sage-fredt5-large  ([дашборд эксперимента](https://wandb.ai/obuchii/transformer_spellers/runs/7ojvllsk), [ноутбук](.experiments/001-model_comparison/005-transformers.ipynb))   | 86.69   | 46.15  | 60.23    | 92.08  | 67.82   |  78.11    |


# Итог

Лучше всего себя показала ai-forever/sage-fredt5-distilled-95m, с хорошей точностью исправляющая и орфографию, и пунктуацию

Она доступна на локально поднимаемом сервере (см README в корневом каталоге)

# Quickstart

Создать venv со всеми зависимостями:

```shell
poetry env use 3.10
poetry install
```

Установить sage (библиотека для измерения качества спеллчека и для самого спеллчека)

```shell
poetry run poe install_sage
```

Запустить сервер

```shell
poetry run poe run_server
```

Swagger будет доступен на `http://127.0.0.1:8000/docs#`

# Структура репозитория

`Dockerfile` - пока рыба с небольшими доработками, на будущее планируется сервер и эксперименты запускать из-под докера, так как не все либы ставятся на виндовс

`src` - исходный код сервера для онлайн-инференса

`sage` - [библиотека](https://github.com/ai-forever/sage/tree/main) проверки орфографии от сбера, ее нет в pip, поэтому установили так

`experiments` - папка со всем ресерчем

Внутри `pyproject.toml` можно посмотреть разные команды

### Приколюхи

Из проиколюх есть:

- nlp_pipeline из коробки, позволяющий ориентироваться на предсказания сразу нескольких моделей

# Release Notes

### wanna todos
- получить апи-ключ опенаи и протестировать чатгпт
- **протестировать модели на текст максимальной длины**
- переписать докстринги
- streamlit-gui
- pdoc
- тест Yandex Spellcheck API
- тест Sage и любой локальной LLM
- хорошая архитектура, devops/mlops и балансировка нагрузки
- ci с тестами

#### 05.09.2024
- проведен эксперимент с ChatGPT - на большом датасете, результаты см [на WandB](https://wandb.ai/obuchii/gpt_spellers_100/table)
- обновлена установка Sage, добавлена команда `reinstall sage`
- протестирован запуск проекта с нуля на новом mac-устройстве, на основе этого исправлена загрузка датасетов в experiments и улучшена стабильность SageModelScorer
- прокинуты настройки автоформаттера и стат анализатора кода в settings.json 

#### 29.08.2024
- реализована модель спеллчека ChatGPT (вариативность моделей + промпт тоже полученный от ChatGPT)
- проведен initial эксперимент (и собрано все окружение) для ChatGPT
- минорные фиксы, код ревью команды ФИЦТО, актуализация мастера

#### 17.08.2024
- реализован dummy-эксперимент для общения с чатгпт
- реализован [ноутбук](https://colab.research.google.com/drive/1QCt1QHD2s7zJGRSrCw_xDVTaJT57MSWL?usp=sharing) с проверкой rugpt3 от сбера (так как ruGPT3.5 не влезает на колаб) - туда можно потыкаться, поменять гиперпараметры и понять, что в текущей реализации rugpt не приспособлена под задачу
- протестирован и доработан сервер и сами модели (багфикс)
- проведен код-ревью [пул-реквеста](https://github.com/AI-Based-Team/Obuch2i-NLP/pull/3/files#diff-4e254ca13938b59c892bf7f6dea06d3f5440006cddca4100805cbeb80fa9b364R221-R224)
- теперь сервер сам перезапускается при обновлении кода
- добавлен автосейв в настройки проекта
- прописана инициализация моделей при первом вызове, а не постоянно
- в src добавлены docstrings
- минорные доработки NLP Pipeline, которую вероятно на будущее надо интегрировать в общий пайплайн


#### 18.07.2024
- запущен тест трансформеров от сбера
- трансформеры добавлены в АПИ отдельным эндпоинтом
- отрефакторил UX работы со Swagger
- (todo) отрефакторить код: вынести базовые классы в base, прописать инициализацию моделей (сейчас она ленивая)
- (todo) при необходимости исправить `explain` у Яндекс модели
- (important todo) прокидывать название модели в параметры эксперимента
- (important todo) перенести вычисления на колаб
- (todo) дозаполнить README экспериментальной репы

### 12.07.2024
- проведен тест Yandex Spellcheck API
- сделан отдельный класс DatasetLoader для улучшения единообразности экспериментов
- реализовано логгирование в WandB
- реализован прототип нейро-чекера правописания
- (туду) добавить в DatasetLoader конкатенацию train и test частей датасета

### 27.06.2024
- сервер с двумя методами: подробное или полное предсказание (пока только одна модель, но при этом гибко собираемый NLP Pipeline)
- плейсхолдеры для cv-моделей (на всякий случай)
- фикс ошибки с SIGALRM
- добавлен тест на пунктуационном датасете (тоже разочаровал)

### 21.06.2024 - initial release

- структура репозитория, зависимости и т.д.
- макет архитектуры сервера
- experiments: датасет орфографии, проверка качества pylanguagetool

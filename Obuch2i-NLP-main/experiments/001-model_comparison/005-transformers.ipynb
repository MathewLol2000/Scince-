{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Проверка орфографии при помощи трансформеров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\lang_check\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Using the latest cached version of the dataset since ai-forever/spellcheck_benchmark couldn't be found on the Hugging Face Hub\n",
      "Found the latest cached dataset configuration 'RUSpellRU' at C:\\Users\\Андрей Т\\.cache\\huggingface\\datasets\\ai-forever___spellcheck_benchmark\\RUSpellRU\\0.0.1\\3395aa540689e4393c3e18d063e73a5b99d7f047 (last modified on Mon Jun 17 00:55:50 2024).\n"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "from src.datasets import load_datasets\n",
    "\n",
    "orpho_dataset, punct_dataset = load_datasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\lang_check\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "import torch\n",
    "from typing import List, Tuple, Dict\n",
    "\n",
    "\n",
    "class TransformerSpellChecker:\n",
    "    \"\"\"\n",
    "    Класс для проверки орфографии и пунктуации с использованием модели на основе Transformers.\n",
    "\n",
    "    Attributes:\n",
    "        tokenizer (AutoTokenizer): Токенизатор для модели.\n",
    "        model (AutoModelForSeq2SeqLM): Модель для генерации исправленного текста.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        model_name: str = \"ai-forever/sage-fredt5-distilled-95m\",\n",
    "        device: str = \"cuda\",\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Инициализация токенизатора и модели.\n",
    "\n",
    "        Args:\n",
    "            model_name (str): Название предобученной модели. По умолчанию \"ai-forever/sage-fredt5-distilled-95m\".\n",
    "            device (str): Устройство для вычислений (\"cuda\" или \"cpu\"). По умолчанию \"cuda\".\n",
    "        \"\"\"\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        self.model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "        self.device = torch.device(device if torch.cuda.is_available() else \"cpu\")\n",
    "        self.model.to(self.device)\n",
    "\n",
    "    def predict_verbose(self, text: str) -> Tuple[List[Dict[str, str]], str]:\n",
    "        \"\"\"\n",
    "        Возвращает исправленный текст и список всех предложенных исправлений.\n",
    "\n",
    "        Args:\n",
    "            text (str): Входной текст для проверки.\n",
    "\n",
    "        Returns:\n",
    "            Tuple[List[Dict[str, str]], str]: Исправленный текст и список всех предложенных исправлений.\n",
    "        \"\"\"\n",
    "        inputs = self.tokenizer(\n",
    "            text,\n",
    "            max_length=None,\n",
    "            padding=\"longest\",\n",
    "            truncation=False,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        outputs = self.model.generate(\n",
    "            **inputs.to(self.model.device), max_length=inputs[\"input_ids\"].size(1) * 1.5\n",
    "        )\n",
    "        corrected_text = self.tokenizer.batch_decode(outputs, skip_special_tokens=True)[\n",
    "            0\n",
    "        ]\n",
    "\n",
    "        corrections = self._generate_corrections(text, corrected_text)\n",
    "        return corrections, corrected_text\n",
    "\n",
    "    def _generate_corrections(\n",
    "        self, original_text: str, corrected_text: str\n",
    "    ) -> List[Dict[str, str]]:\n",
    "        \"\"\"\n",
    "        Генерирует список исправлений на основе оригинального и исправленного текста.\n",
    "\n",
    "        Args:\n",
    "            original_text (str): Оригинальный текст.\n",
    "            corrected_text (str): Исправленный текст.\n",
    "\n",
    "        Returns:\n",
    "            List[Dict[str, str]]: Список исправлений.\n",
    "        \"\"\"\n",
    "        corrections = []\n",
    "        original_words = original_text.split()\n",
    "        corrected_words = corrected_text.split()\n",
    "\n",
    "        # Идем по минимальной длине списков\n",
    "        for idx, (original_word, corrected_word) in enumerate(\n",
    "            zip(original_words, corrected_words)\n",
    "        ):\n",
    "            if original_word != corrected_word:\n",
    "                correction = {\n",
    "                    \"index\": original_text.index(original_word),\n",
    "                    \"error\": original_word,\n",
    "                    \"suggestions\": [corrected_word],\n",
    "                    \"message\": \"\",\n",
    "                }\n",
    "                corrections.append(correction)\n",
    "\n",
    "        # Если есть оставшиеся слова в оригинальном тексте\n",
    "        if len(original_words) > len(corrected_words):\n",
    "            for word in original_words[len(corrected_words) :]:\n",
    "                correction = {\n",
    "                    \"index\": original_text.index(word),\n",
    "                    \"error\": word,\n",
    "                    \"suggestions\": [],\n",
    "                    \"message\": \"\",\n",
    "                }\n",
    "                corrections.append(correction)\n",
    "\n",
    "        # Если есть добавленные слова в исправленном тексте\n",
    "        if len(corrected_words) > len(original_words):\n",
    "            for word in corrected_words[len(original_words) :]:\n",
    "                correction = {\n",
    "                    \"index\": len(original_text),\n",
    "                    \"error\": \"\",\n",
    "                    \"suggestions\": [word],\n",
    "                    \"message\": \"\",\n",
    "                }\n",
    "                corrections.append(correction)\n",
    "\n",
    "        return corrections\n",
    "\n",
    "    def predict(self, text: str) -> str:\n",
    "        \"\"\"\n",
    "        Возвращает исправленный текст.\n",
    "\n",
    "        Args:\n",
    "            text (str): Входной текст для проверки.\n",
    "\n",
    "        Returns:\n",
    "            str: Исправленный текст.\n",
    "        \"\"\"\n",
    "        _, corrected_text = self.predict_verbose(text)\n",
    "        return corrected_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = TransformerSpellChecker()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задаем список моделей, которые будем тестировать (в порядке их приоритета)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_NAME = \"transformer_spellers\"\n",
    "\n",
    "MODEL_NAMES = [\n",
    "    \"sage-fredt5-distilled-95m\",\n",
    "    \"sage-fredt5-large\",\n",
    "    \"sage-m2m100-1.2B\",\n",
    "    \"sage-mt5-large\",\n",
    "]\n",
    "MODEL_NAMES = map(lambda x: f\"ai-forever/{x}\", MODEL_NAMES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "from src.model_scorers import WandbSageModelScorer\n",
    "\n",
    "\n",
    "def _score_model(mode: str, dataset, model_name: str):\n",
    "    sms = WandbSageModelScorer(dataset, project=PROJECT_NAME, run_suffix=mode)\n",
    "    model = TransformerSpellChecker(model_name)\n",
    "    scoring_final_result, explanation = sms.score_explain(\n",
    "        model, metrics=[\"errant\", \"ruspelleval\"]\n",
    "    )\n",
    "    print(f\"{model_name} ({mode}):\")\n",
    "    print(scoring_final_result, explanation, sep=\"\\n\\n\\n\")\n",
    "    return scoring_final_result, explanation\n",
    "\n",
    "\n",
    "def score(mode: Literal[\"orpho\"] | Literal[\"punct\"], model_name):\n",
    "    if mode == \"orpho\":\n",
    "        _score_model(\n",
    "            mode=\"orpho\",\n",
    "            dataset=orpho_dataset[\"test\"],\n",
    "            model_name=model_name,\n",
    "        )\n",
    "    elif mode == \"punct\":\n",
    "        _score_model(\n",
    "            mode=\"punct\",\n",
    "            dataset=punct_dataset[\"test\"],\n",
    "            model_name=model_name,\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError(\"No such mode\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Тестирование: орфография и пунктуация\n",
    "\n",
    "Эксперимент до конца не завершён - \"железа\" не хватило на все модели\n",
    "\n",
    "Будет перезапущен на Google Colab (GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mandtun\u001b[0m (\u001b[33mobuchii\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\lang_check\\experiments\\001-model_comparison\\wandb\\run-20240719_043703-cj4hf61p</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/obuchii/transformer_spellers/runs/cj4hf61p' target=\"_blank\">summer-eon-6</a></strong> to <a href='https://wandb.ai/obuchii/transformer_spellers' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/obuchii/transformer_spellers' target=\"_blank\">https://wandb.ai/obuchii/transformer_spellers</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/obuchii/transformer_spellers/runs/cj4hf61p' target=\"_blank\">https://wandb.ai/obuchii/transformer_spellers/runs/cj4hf61p</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "100%|██████████| 2008/2008 [24:16<00:00,  1.38it/s] \n",
      "Calculating errant metric: 100%|██████████| 2008/2008 [01:39<00:00, 20.24it/s]\n",
      "Calculating words metric: 100%|██████████| 2008/2008 [00:06<00:00, 316.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ai-forever/sage-fredt5-distilled-95m (orpho):\n",
      "{'SPELL_Precision': 64.74, 'SPELL_Recall': 68.91, 'SPELL_F1': 66.76, 'PUNCT_Precision': 0.02, 'PUNCT_Recall': 33.33, 'PUNCT_F1': 0.04, 'CASE_Precision': 0.0, 'CASE_Recall': 100.0, 'CASE_F1': 0.0, 'YO_Precision': 0.0, 'YO_Recall': 100.0, 'YO_F1': 0.0, 'Precision': 82.19, 'Recall': 77.25, 'F1': 79.65}\n",
      "\n",
      "\n",
      "                                                 Source  \\\n",
      "0        ﻿есть у вас оформленый и подписаный мною заказ   \n",
      "1     вот в инете откапал такую интеерсную статейку ...   \n",
      "2     я на всю жизнь запомню свое первое купание в з...   \n",
      "3     думаем что не ошибемся если скажем что выставк...   \n",
      "4     судьба человека может складываться очень разно...   \n",
      "...                                                 ...   \n",
      "2003  спасибо вам огромное за нормальную новость о е...   \n",
      "2004  более захватывающее и наглядное обучение возмо...   \n",
      "2005  и вобщем-то все понятно на фоне слухов застави...   \n",
      "2006                               но всему есть придел   \n",
      "2007  у нас в доме оччень много застекленных вертика...   \n",
      "\n",
      "                                                  Truth  \\\n",
      "0      ﻿есть у вас оформленный и подписанный мною заказ   \n",
      "1     вот в инете откопал такую интересную статейку ...   \n",
      "2     я на всю жизнь запомню свое первое купание в з...   \n",
      "3     думаем что не ошибемся если скажем что выставк...   \n",
      "4     судьба человека может складываться очень разно...   \n",
      "...                                                 ...   \n",
      "2003  спасибо вам огромное за нормальную новость о е...   \n",
      "2004  более захватывающее и наглядное обучение возмо...   \n",
      "2005  и в общем-то все понятно на фоне слухов застав...   \n",
      "2006                               но всему есть предел   \n",
      "2007  у нас в доме очень много застекленных вертикал...   \n",
      "\n",
      "                                           Model_result  Model_is_correct  \n",
      "0      Есть у вас оформленный и подписанный мною заказ.             False  \n",
      "1     Вот в Инете откапал такую интересную статейку,...             False  \n",
      "2     Я на всю жизнь запомню своё первое купание в з...             False  \n",
      "3     Думаем, что не ошибемся, если скажем, что выст...             False  \n",
      "4     Судьба человека может складываться очень разно...             False  \n",
      "...                                                 ...               ...  \n",
      "2003  Спасибо вам огромное за нормальную новость о е...             False  \n",
      "2004  Более захватывающее и наглядное обучение возмо...             False  \n",
      "2005  И, в общем-то, всё понятно на фоне слухов заст...             False  \n",
      "2006                              Но всему есть предел.             False  \n",
      "2007  У нас в доме очень много застекленных вертикал...             False  \n",
      "\n",
      "[2008 rows x 4 columns]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:cj4hf61p) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">summer-eon-6</strong> at: <a href='https://wandb.ai/obuchii/transformer_spellers/runs/cj4hf61p' target=\"_blank\">https://wandb.ai/obuchii/transformer_spellers/runs/cj4hf61p</a><br/> View project at: <a href='https://wandb.ai/obuchii/transformer_spellers' target=\"_blank\">https://wandb.ai/obuchii/transformer_spellers</a><br/>Synced 5 W&B file(s), 1 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240719_043703-cj4hf61p\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:cj4hf61p). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\lang_check\\experiments\\001-model_comparison\\wandb\\run-20240719_050337-21macwva</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/obuchii/transformer_spellers/runs/21macwva' target=\"_blank\">clean-lion-7</a></strong> to <a href='https://wandb.ai/obuchii/transformer_spellers' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/obuchii/transformer_spellers' target=\"_blank\">https://wandb.ai/obuchii/transformer_spellers</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/obuchii/transformer_spellers/runs/21macwva' target=\"_blank\">https://wandb.ai/obuchii/transformer_spellers/runs/21macwva</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "100%|██████████| 2008/2008 [20:42<00:00,  1.62it/s]\n",
      "Calculating errant metric: 100%|██████████| 2008/2008 [01:30<00:00, 22.22it/s]\n",
      "Calculating words metric: 100%|██████████| 2008/2008 [00:05<00:00, 348.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ai-forever/sage-fredt5-distilled-95m (punct):\n",
      "{'CASE_Precision': 94.37, 'CASE_Recall': 92.55, 'CASE_F1': 93.45, 'SPELL_Precision': 77.49, 'SPELL_Recall': 64.09, 'SPELL_F1': 70.15, 'PUNCT_Precision': 86.78, 'PUNCT_Recall': 80.57, 'PUNCT_F1': 83.56, 'YO_Precision': 46.21, 'YO_Recall': 73.83, 'YO_F1': 56.84, 'Precision': 83.43, 'Recall': 74.75, 'F1': 78.85}\n",
      "\n",
      "\n",
      "                                                 Source  \\\n",
      "0     а так хочеться что-то мочь менять в этом мире ...   \n",
      "1     давольно милый и летом и зимой обогреваемый те...   \n",
      "2     бывают такие моменты когда хочеться зделать чт...   \n",
      "3        ﻿есть у вас оформленый и подписаный мною заказ   \n",
      "4     вот в инете откапал такую интеерсную статейку ...   \n",
      "...                                                 ...   \n",
      "2003  спасибо вам огромное за нормальную новость о е...   \n",
      "2004  более захватывающее и наглядное обучение возмо...   \n",
      "2005  и вобщем-то все понятно на фоне слухов застави...   \n",
      "2006                               но всему есть придел   \n",
      "2007  у нас в доме оччень много застекленных вертика...   \n",
      "\n",
      "                                                  Truth  \\\n",
      "0     А так хочется что-то мочь менять в этом мире: ...   \n",
      "1     Довольно милый, и летом, и зимой обогреваемый ...   \n",
      "2     Бывают такие моменты, когда хочется сделать чт...   \n",
      "3     ﻿Есть у вас оформленный и подписанный мною заказ?   \n",
      "4     Вот в инете откопал такую интересную статейку,...   \n",
      "...                                                 ...   \n",
      "2003  Спасибо вам огромное за нормальную новость о Ё...   \n",
      "2004  Более захватывающее и наглядное обучение возмо...   \n",
      "2005  И, в общем-то, всё понятно на фоне слухов: зас...   \n",
      "2006                              Но всему есть предел.   \n",
      "2007  У нас в доме очень много застеклённых вертикал...   \n",
      "\n",
      "                                           Model_result  Model_is_correct  \n",
      "0     А так хочется что-то мочь менять в этом мире: ...              True  \n",
      "1     Довольно милый, и летом, и зимой обогреваемый ...              True  \n",
      "2     Бывают такие моменты, когда хочется сделать чт...              True  \n",
      "3      Есть у вас оформленный и подписанный мною заказ.             False  \n",
      "4     Вот в Инете откапал такую интересную статейку,...             False  \n",
      "...                                                 ...               ...  \n",
      "2003  Спасибо вам огромное за нормальную новость о е...             False  \n",
      "2004  Более захватывающее и наглядное обучение возмо...             False  \n",
      "2005  И, в общем-то, всё понятно на фоне слухов заст...             False  \n",
      "2006                              Но всему есть предел.              True  \n",
      "2007  У нас в доме очень много застекленных вертикал...             False  \n",
      "\n",
      "[2008 rows x 4 columns]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:21macwva) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">clean-lion-7</strong> at: <a href='https://wandb.ai/obuchii/transformer_spellers/runs/21macwva' target=\"_blank\">https://wandb.ai/obuchii/transformer_spellers/runs/21macwva</a><br/> View project at: <a href='https://wandb.ai/obuchii/transformer_spellers' target=\"_blank\">https://wandb.ai/obuchii/transformer_spellers</a><br/>Synced 5 W&B file(s), 1 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240719_050337-21macwva\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:21macwva). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\lang_check\\experiments\\001-model_comparison\\wandb\\run-20240719_052637-w4g1na9g</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/obuchii/transformer_spellers/runs/w4g1na9g' target=\"_blank\">dauntless-wave-8</a></strong> to <a href='https://wandb.ai/obuchii/transformer_spellers' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/obuchii/transformer_spellers' target=\"_blank\">https://wandb.ai/obuchii/transformer_spellers</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/obuchii/transformer_spellers/runs/w4g1na9g' target=\"_blank\">https://wandb.ai/obuchii/transformer_spellers/runs/w4g1na9g</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\lang_check\\.venv\\lib\\site-packages\\huggingface_hub\\file_download.py:157: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Андрей Т\\.cache\\huggingface\\hub\\models--ai-forever--sage-fredt5-large. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "100%|██████████| 2008/2008 [1:55:45<00:00,  3.46s/it]  \n",
      "Calculating errant metric: 100%|██████████| 2008/2008 [02:14<00:00, 14.89it/s]\n",
      "Calculating words metric: 100%|██████████| 2008/2008 [00:07<00:00, 285.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ai-forever/sage-fredt5-large (orpho):\n",
      "{'SPELL_Precision': 52.07, 'SPELL_Recall': 67.5, 'SPELL_F1': 58.79, 'CASE_Precision': 0.0, 'CASE_Recall': 100.0, 'CASE_F1': 0.0, 'PUNCT_Precision': 0.03, 'PUNCT_Recall': 33.33, 'PUNCT_F1': 0.06, 'YO_Precision': 0.0, 'YO_Recall': 100.0, 'YO_F1': 0.0, 'Precision': 56.75, 'Recall': 70.58, 'F1': 62.91}\n",
      "\n",
      "\n",
      "                                                 Source  \\\n",
      "0        ﻿есть у вас оформленый и подписаный мною заказ   \n",
      "1     вот в инете откапал такую интеерсную статейку ...   \n",
      "2     я на всю жизнь запомню свое первое купание в з...   \n",
      "3     думаем что не ошибемся если скажем что выставк...   \n",
      "4     судьба человека может складываться очень разно...   \n",
      "...                                                 ...   \n",
      "2003  спасибо вам огромное за нормальную новость о е...   \n",
      "2004  более захватывающее и наглядное обучение возмо...   \n",
      "2005  и вобщем-то все понятно на фоне слухов застави...   \n",
      "2006                               но всему есть придел   \n",
      "2007  у нас в доме оччень много застекленных вертика...   \n",
      "\n",
      "                                                  Truth  \\\n",
      "0      ﻿есть у вас оформленный и подписанный мною заказ   \n",
      "1     вот в инете откопал такую интересную статейку ...   \n",
      "2     я на всю жизнь запомню свое первое купание в з...   \n",
      "3     думаем что не ошибемся если скажем что выставк...   \n",
      "4     судьба человека может складываться очень разно...   \n",
      "...                                                 ...   \n",
      "2003  спасибо вам огромное за нормальную новость о е...   \n",
      "2004  более захватывающее и наглядное обучение возмо...   \n",
      "2005  и в общем-то все понятно на фоне слухов застав...   \n",
      "2006                               но всему есть предел   \n",
      "2007  у нас в доме очень много застекленных вертикал...   \n",
      "\n",
      "                                           Model_result  Model_is_correct  \n",
      "0     \\\\есть у вас оформленный и подписанный мною заказ             False  \n",
      "1     вот в инете откопал такую интересную статейку ...              True  \n",
      "2     Я на всю жизнь запомню свое первое купание в з...             False  \n",
      "3     думаем, что не ошибемся, если скажем, что выст...             False  \n",
      "4     Судьба человека может складываться очень разно...             False  \n",
      "...                                                 ...               ...  \n",
      "2003  Спасибо вам огромное за нормальную новость о е...              True  \n",
      "2004  Более захватывающее и наглядное обучение возмо...             False  \n",
      "2005  И в общем-то все понятно на фоне слухов застав...             False  \n",
      "2006                               Но всему есть предел              True  \n",
      "2007  У нас в доме очень много застекленных вертикал...             False  \n",
      "\n",
      "[2008 rows x 4 columns]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:w4g1na9g) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">dauntless-wave-8</strong> at: <a href='https://wandb.ai/obuchii/transformer_spellers/runs/w4g1na9g' target=\"_blank\">https://wandb.ai/obuchii/transformer_spellers/runs/w4g1na9g</a><br/> View project at: <a href='https://wandb.ai/obuchii/transformer_spellers' target=\"_blank\">https://wandb.ai/obuchii/transformer_spellers</a><br/>Synced 5 W&B file(s), 1 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240719_052637-w4g1na9g\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:w4g1na9g). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\lang_check\\experiments\\001-model_comparison\\wandb\\run-20240719_072744-7ojvllsk</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/obuchii/transformer_spellers/runs/7ojvllsk' target=\"_blank\">silver-elevator-9</a></strong> to <a href='https://wandb.ai/obuchii/transformer_spellers' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/obuchii/transformer_spellers' target=\"_blank\">https://wandb.ai/obuchii/transformer_spellers</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/obuchii/transformer_spellers/runs/7ojvllsk' target=\"_blank\">https://wandb.ai/obuchii/transformer_spellers/runs/7ojvllsk</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "100%|██████████| 2008/2008 [10:25:58<00:00, 18.70s/it]    \n",
      "Calculating errant metric: 100%|██████████| 2008/2008 [02:46<00:00, 12.05it/s]\n",
      "Calculating words metric: 100%|██████████| 2008/2008 [00:08<00:00, 249.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ai-forever/sage-fredt5-large (punct):\n",
      "{'CASE_Precision': 92.08, 'CASE_Recall': 67.82, 'CASE_F1': 78.11, 'SPELL_Precision': 55.2, 'SPELL_Recall': 55.59, 'SPELL_F1': 55.39, 'PUNCT_Precision': 86.69, 'PUNCT_Recall': 46.15, 'PUNCT_F1': 60.23, 'YO_Precision': 0.0, 'YO_Recall': 0.0, 'YO_F1': 0.0, 'Precision': 57.44, 'Recall': 68.1, 'F1': 62.32}\n",
      "\n",
      "\n",
      "                                                 Source  \\\n",
      "0     а так хочеться что-то мочь менять в этом мире ...   \n",
      "1     давольно милый и летом и зимой обогреваемый те...   \n",
      "2     бывают такие моменты когда хочеться зделать чт...   \n",
      "3        ﻿есть у вас оформленый и подписаный мною заказ   \n",
      "4     вот в инете откапал такую интеерсную статейку ...   \n",
      "...                                                 ...   \n",
      "2003  спасибо вам огромное за нормальную новость о е...   \n",
      "2004  более захватывающее и наглядное обучение возмо...   \n",
      "2005  и вобщем-то все понятно на фоне слухов застави...   \n",
      "2006                               но всему есть придел   \n",
      "2007  у нас в доме оччень много застекленных вертика...   \n",
      "\n",
      "                                                  Truth  \\\n",
      "0     А так хочется что-то мочь менять в этом мире: ...   \n",
      "1     Довольно милый, и летом, и зимой обогреваемый ...   \n",
      "2     Бывают такие моменты, когда хочется сделать чт...   \n",
      "3     ﻿Есть у вас оформленный и подписанный мною заказ?   \n",
      "4     Вот в инете откопал такую интересную статейку,...   \n",
      "...                                                 ...   \n",
      "2003  Спасибо вам огромное за нормальную новость о Ё...   \n",
      "2004  Более захватывающее и наглядное обучение возмо...   \n",
      "2005  И, в общем-то, всё понятно на фоне слухов: зас...   \n",
      "2006                              Но всему есть предел.   \n",
      "2007  У нас в доме очень много застеклённых вертикал...   \n",
      "\n",
      "                                           Model_result  Model_is_correct  \n",
      "0     А так хочется что-то начать менять в этом мире...             False  \n",
      "1     довольно милый и летом и зимой обогреваемый те...             False  \n",
      "2     Бывают такие моменты, когда хочется сделать чт...              True  \n",
      "3     \\\\есть у вас оформленный и подписанный мною заказ             False  \n",
      "4     вот в инете откопал такую интересную статейку ...             False  \n",
      "...                                                 ...               ...  \n",
      "2003  Спасибо вам огромное за нормальную новость о е...             False  \n",
      "2004  Более захватывающее и наглядное обучение возмо...             False  \n",
      "2005  И в общем-то все понятно на фоне слухов застав...             False  \n",
      "2006                               Но всему есть предел             False  \n",
      "2007  У нас в доме очень много застекленных вертикал...             False  \n",
      "\n",
      "[2008 rows x 4 columns]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:7ojvllsk) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">silver-elevator-9</strong> at: <a href='https://wandb.ai/obuchii/transformer_spellers/runs/7ojvllsk' target=\"_blank\">https://wandb.ai/obuchii/transformer_spellers/runs/7ojvllsk</a><br/> View project at: <a href='https://wandb.ai/obuchii/transformer_spellers' target=\"_blank\">https://wandb.ai/obuchii/transformer_spellers</a><br/>Synced 5 W&B file(s), 1 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240719_072744-7ojvllsk\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:7ojvllsk). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\lang_check\\experiments\\001-model_comparison\\wandb\\run-20240719_175758-gb086g26</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/obuchii/transformer_spellers/runs/gb086g26' target=\"_blank\">desert-energy-10</a></strong> to <a href='https://wandb.ai/obuchii/transformer_spellers' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/obuchii/transformer_spellers' target=\"_blank\">https://wandb.ai/obuchii/transformer_spellers</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/obuchii/transformer_spellers/runs/gb086g26' target=\"_blank\">https://wandb.ai/obuchii/transformer_spellers/runs/gb086g26</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\lang_check\\.venv\\lib\\site-packages\\huggingface_hub\\file_download.py:157: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Андрей Т\\.cache\\huggingface\\hub\\models--ai-forever--sage-m2m100-1.2B. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "Unable to load vocabulary from file. Please check that the provided vocabulary is accessible and not corrupted.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "File \u001b[1;32mc:\\lang_check\\.venv\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2397\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase._from_pretrained\u001b[1;34m(cls, resolved_vocab_files, pretrained_model_name_or_path, init_configuration, token, cache_dir, local_files_only, _commit_hash, _is_local, trust_remote_code, *init_inputs, **kwargs)\u001b[0m\n\u001b[0;32m   2396\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 2397\u001b[0m     tokenizer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m(\u001b[38;5;241m*\u001b[39minit_inputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minit_kwargs)\n\u001b[0;32m   2398\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\lang_check\\.venv\\lib\\site-packages\\transformers\\models\\m2m_100\\tokenization_m2m_100.py:144\u001b[0m, in \u001b[0;36mM2M100Tokenizer.__init__\u001b[1;34m(self, vocab_file, spm_file, src_lang, tgt_lang, bos_token, eos_token, sep_token, pad_token, unk_token, language_codes, sp_model_kwargs, num_madeup_words, **kwargs)\u001b[0m\n\u001b[0;32m    143\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspm_file \u001b[38;5;241m=\u001b[39m spm_file\n\u001b[1;32m--> 144\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msp_model \u001b[38;5;241m=\u001b[39m \u001b[43mload_spm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspm_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msp_model_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    146\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder)\n",
      "File \u001b[1;32mc:\\lang_check\\.venv\\lib\\site-packages\\transformers\\models\\m2m_100\\tokenization_m2m_100.py:368\u001b[0m, in \u001b[0;36mload_spm\u001b[1;34m(path, sp_model_kwargs)\u001b[0m\n\u001b[0;32m    367\u001b[0m spm \u001b[38;5;241m=\u001b[39m sentencepiece\u001b[38;5;241m.\u001b[39mSentencePieceProcessor(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39msp_model_kwargs)\n\u001b[1;32m--> 368\u001b[0m \u001b[43mspm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLoad\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    369\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m spm\n",
      "File \u001b[1;32mc:\\lang_check\\.venv\\lib\\site-packages\\sentencepiece\\__init__.py:961\u001b[0m, in \u001b[0;36mSentencePieceProcessor.Load\u001b[1;34m(self, model_file, model_proto)\u001b[0m\n\u001b[0;32m    960\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mLoadFromSerializedProto(model_proto)\n\u001b[1;32m--> 961\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLoadFromFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_file\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\lang_check\\.venv\\lib\\site-packages\\sentencepiece\\__init__.py:316\u001b[0m, in \u001b[0;36mSentencePieceProcessor.LoadFromFile\u001b[1;34m(self, arg)\u001b[0m\n\u001b[0;32m    315\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mLoadFromFile\u001b[39m(\u001b[38;5;28mself\u001b[39m, arg):\n\u001b[1;32m--> 316\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_sentencepiece\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSentencePieceProcessor_LoadFromFile\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marg\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mOSError\u001b[0m: Not found: \"C:\\Users\\Андрей Т\\.cache\\huggingface\\hub\\models--ai-forever--sage-m2m100-1.2B\\snapshots\\1773f13bcbf21d7d945a3ba58473acac3aea6690\\sentencepiece.bpe.model\": No such file or directory Error #2",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m model_name \u001b[38;5;129;01min\u001b[39;00m MODEL_NAMES:\n\u001b[1;32m----> 2\u001b[0m     \u001b[43mscore\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43morpho\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m     score(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpunct\u001b[39m\u001b[38;5;124m\"\u001b[39m, model_name)\n",
      "Cell \u001b[1;32mIn[4], line 18\u001b[0m, in \u001b[0;36mscore\u001b[1;34m(mode, model_name)\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mscore\u001b[39m(mode: Literal[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124morpho\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m|\u001b[39m Literal[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpunct\u001b[39m\u001b[38;5;124m\"\u001b[39m], model_name):\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124morpho\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m---> 18\u001b[0m         \u001b[43m_score_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43morpho\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morpho_dataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtest\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpunct\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m     24\u001b[0m         _score_model(\n\u001b[0;32m     25\u001b[0m             mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpunct\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     26\u001b[0m             dataset\u001b[38;5;241m=\u001b[39mpunct_dataset[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m     27\u001b[0m             model_name\u001b[38;5;241m=\u001b[39mmodel_name,\n\u001b[0;32m     28\u001b[0m         )\n",
      "Cell \u001b[1;32mIn[4], line 7\u001b[0m, in \u001b[0;36m_score_model\u001b[1;34m(mode, dataset, model_name)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_score_model\u001b[39m(mode: \u001b[38;5;28mstr\u001b[39m, dataset, model_name: \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m      6\u001b[0m     sms \u001b[38;5;241m=\u001b[39m WandbSageModelScorer(dataset, project\u001b[38;5;241m=\u001b[39mPROJECT_NAME, run_suffix\u001b[38;5;241m=\u001b[39mmode)\n\u001b[1;32m----> 7\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mTransformerSpellChecker\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m     scoring_final_result, explanation \u001b[38;5;241m=\u001b[39m sms\u001b[38;5;241m.\u001b[39mscore_explain(\n\u001b[0;32m      9\u001b[0m         model, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merrant\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mruspelleval\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     10\u001b[0m     )\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmode\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m):\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[2], line 27\u001b[0m, in \u001b[0;36mTransformerSpellChecker.__init__\u001b[1;34m(self, model_name, device)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m     17\u001b[0m     model_name: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mai-forever/sage-fredt5-distilled-95m\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     18\u001b[0m     device: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     19\u001b[0m ):\n\u001b[0;32m     20\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;124;03m    Инициализация токенизатора и модели.\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;124;03m        device (str): Устройство для вычислений (\"cuda\" или \"cpu\"). По умолчанию \"cuda\".\u001b[39;00m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 27\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer \u001b[38;5;241m=\u001b[39m \u001b[43mAutoTokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     28\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m AutoModelForSeq2SeqLM\u001b[38;5;241m.\u001b[39mfrom_pretrained(model_name)\n\u001b[0;32m     29\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(device \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\lang_check\\.venv\\lib\\site-packages\\transformers\\models\\auto\\tokenization_auto.py:889\u001b[0m, in \u001b[0;36mAutoTokenizer.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, *inputs, **kwargs)\u001b[0m\n\u001b[0;32m    885\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m tokenizer_class \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    886\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    887\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTokenizer class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtokenizer_class_candidate\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not exist or is not currently imported.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    888\u001b[0m         )\n\u001b[1;32m--> 889\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tokenizer_class\u001b[38;5;241m.\u001b[39mfrom_pretrained(pretrained_model_name_or_path, \u001b[38;5;241m*\u001b[39minputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    891\u001b[0m \u001b[38;5;66;03m# Otherwise we have to be creative.\u001b[39;00m\n\u001b[0;32m    892\u001b[0m \u001b[38;5;66;03m# if model is an encoder decoder, the encoder tokenizer class is used by default\u001b[39;00m\n\u001b[0;32m    893\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(config, EncoderDecoderConfig):\n",
      "File \u001b[1;32mc:\\lang_check\\.venv\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2163\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, cache_dir, force_download, local_files_only, token, revision, trust_remote_code, *init_inputs, **kwargs)\u001b[0m\n\u001b[0;32m   2160\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2161\u001b[0m         logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloading file \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m from cache at \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresolved_vocab_files[file_id]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 2163\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_from_pretrained(\n\u001b[0;32m   2164\u001b[0m     resolved_vocab_files,\n\u001b[0;32m   2165\u001b[0m     pretrained_model_name_or_path,\n\u001b[0;32m   2166\u001b[0m     init_configuration,\n\u001b[0;32m   2167\u001b[0m     \u001b[38;5;241m*\u001b[39minit_inputs,\n\u001b[0;32m   2168\u001b[0m     token\u001b[38;5;241m=\u001b[39mtoken,\n\u001b[0;32m   2169\u001b[0m     cache_dir\u001b[38;5;241m=\u001b[39mcache_dir,\n\u001b[0;32m   2170\u001b[0m     local_files_only\u001b[38;5;241m=\u001b[39mlocal_files_only,\n\u001b[0;32m   2171\u001b[0m     _commit_hash\u001b[38;5;241m=\u001b[39mcommit_hash,\n\u001b[0;32m   2172\u001b[0m     _is_local\u001b[38;5;241m=\u001b[39mis_local,\n\u001b[0;32m   2173\u001b[0m     trust_remote_code\u001b[38;5;241m=\u001b[39mtrust_remote_code,\n\u001b[0;32m   2174\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   2175\u001b[0m )\n",
      "File \u001b[1;32mc:\\lang_check\\.venv\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2399\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase._from_pretrained\u001b[1;34m(cls, resolved_vocab_files, pretrained_model_name_or_path, init_configuration, token, cache_dir, local_files_only, _commit_hash, _is_local, trust_remote_code, *init_inputs, **kwargs)\u001b[0m\n\u001b[0;32m   2397\u001b[0m     tokenizer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m(\u001b[38;5;241m*\u001b[39minit_inputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minit_kwargs)\n\u001b[0;32m   2398\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[1;32m-> 2399\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\n\u001b[0;32m   2400\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnable to load vocabulary from file. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2401\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease check that the provided vocabulary is accessible and not corrupted.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2402\u001b[0m     )\n\u001b[0;32m   2404\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m added_tokens_decoder \u001b[38;5;241m!=\u001b[39m {} \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;28mlist\u001b[39m(added_tokens_decoder\u001b[38;5;241m.\u001b[39mkeys())[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], \u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m>\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mvocab_size:\n\u001b[0;32m   2405\u001b[0m     logger\u001b[38;5;241m.\u001b[39mwarning_advice(\n\u001b[0;32m   2406\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSpecial tokens have been added in the vocabulary, make sure the associated word embeddings are\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2407\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m fine-tuned or trained.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2408\u001b[0m     )\n",
      "\u001b[1;31mOSError\u001b[0m: Unable to load vocabulary from file. Please check that the provided vocabulary is accessible and not corrupted."
     ]
    }
   ],
   "source": [
    "for model_name in MODEL_NAMES:\n",
    "    score(\"orpho\", model_name)\n",
    "    score(\"punct\", model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'finish'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mwandb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfinish\u001b[49m()\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'finish'"
     ]
    }
   ],
   "source": [
    "wandb.run.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Выводы\n",
    "\n",
    "### ai-forever/sage-fredt5-distilled-95m\n",
    "\n",
    "https://wandb.ai/obuchii/transformer_spellers/runs/cj4hf61p\n",
    "\n",
    "|  Задача | Errant Precision | Errant Recall | Errant F1 | Precision | Recall | F1\n",
    "|----------|----------|----------|----------|----------|----------|----------|\n",
    "| Spelling   | 64.74   | 68.91   | 66.76    | 82.19   | 77.25   | 79.65   |\n",
    "\n",
    "-------\n",
    "\n",
    "\n",
    " https://wandb.ai/obuchii/transformer_spellers/runs/21macwva\n",
    " \n",
    "|  Задача | Punct Precision | Punct Recall | Punct F1 | Case Precision | Case Recall | Case F1\n",
    "|----------|----------|----------|----------|----------|----------|----------|\n",
    "| Punctuation   | 86.78   | 80.57   | 83.56   |  94.37  | 92.55   | 93.45   |\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### ai-forever/sage-fredt5-large\n",
    "\n",
    "https://wandb.ai/obuchii/transformer_spellers/runs/w4g1na9g\n",
    "\n",
    "|  Задача | Errant Precision | Errant Recall | Errant F1 | Precision | Recall | F1\n",
    "|----------|----------|----------|----------|----------|----------|----------|\n",
    "| Spelling   | 52.07   | 67.5   | 58.79   | 56.75  | 70.58  | 62.91    |\n",
    "\n",
    "-------\n",
    "\n",
    "  https://wandb.ai/obuchii/transformer_spellers/runs/7ojvllsk\n",
    "\n",
    " \n",
    "|  Задача | Punct Precision | Punct Recall | Punct F1 | Case Precision | Case Recall | Case F1\n",
    "|----------|----------|----------|----------|----------|----------|----------|\n",
    "| Punctuation   | 86.69   | 46.15  | 60.23    | 92.08  | 67.82   |  78.11    |\n",
    "\n",
    "\n",
    "# Итог\n",
    "\n",
    "Лучше всего себя показала ai-forever/sage-fredt5-distilled-95m, с хорошей точностью исправляющая и орфографию, и пунктуацию\n",
    "\n",
    "Она доступна на локально поднимаемом сервере (см README в корневом каталоге)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
